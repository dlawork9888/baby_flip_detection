{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de68a11-8444-43f5-a95d-ad264dcff4d6",
   "metadata": {},
   "source": [
    "# flip_detection_modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d37780-364f-4ce8-af2b-0b8eca810746",
   "metadata": {},
   "source": [
    "ipynb로 바로 실행해볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9afe9d7d-f85a-445f-8887-95446b5e3d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67d40106-8e5e-41a8-8a3f-ca8ef6d7765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a037625-5af5-41f4-81e7-e40c1307e1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mediapipe\n",
      "Version: 0.10.0\n",
      "Summary: MediaPipe is the simplest way for researchers and developers to build world-class ML solutions and applications for mobile, edge, cloud and the web.\n",
      "Home-page: https://github.com/google/mediapipe\n",
      "Author: The MediaPipe Authors\n",
      "Author-email: mediapipe@google.com\n",
      "License: Apache 2.0\n",
      "Location: c:\\flyai\\envs\\mediapipe_env_2\\lib\\site-packages\n",
      "Requires: absl-py, attrs, flatbuffers, matplotlib, numpy, opencv-contrib-python, protobuf, sounddevice\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35157378-c794-4ca6-b501-962552826123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.3'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb5d0203-f746-48a4-92c6-204226ad5368",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 수선의 발 산출 모듈\n",
    "# A에서 BC에 내린 수선의 발 좌표 return\n",
    "def find_perpendicular_foot(A, B, C): \n",
    "    \n",
    "    # A,B,C => np.array([float, float])\n",
    "    # return => np.array([float, float])\n",
    "    \n",
    "    BC = C - B\n",
    "    BC_length_squared = np.dot(BC, BC)\n",
    "    BA_dot_BC = np.dot(A - B, BC)\n",
    "    t = BA_dot_BC / BC_length_squared\n",
    "    foot = B + t * BC\n",
    "    \n",
    "    return foot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14c6bd6f-f31f-4b3d-ba4b-1718dfecce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 회전 변환 모듈\n",
    "# point를 theta만큼 회전 변환, 이때는 원점 기준\n",
    "def rotate_point(point, theta): \n",
    "\n",
    "    # point => np.array, theta => np.radians\n",
    "    # return => np.array\n",
    "    \n",
    "    rotation_matrix = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                                 [np.sin(theta), np.cos(theta)]])\n",
    "    rotated_point = np.dot(rotation_matrix, point)\n",
    "\n",
    "    return rotated_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93268fbc-4e6c-41df-a046-d15bb3c01670",
   "metadata": {},
   "outputs": [],
   "source": [
    "### flip_detection 모듈 \n",
    "\n",
    "def is_flipped(foot, nose, left_s, right_s): \n",
    "\n",
    "    # foot, nose, left_s, right_s => np.array([float, float])\n",
    "    # return => bool\n",
    "\n",
    "    # foot만큼 평행이동(foot이 원점으로)\n",
    "    nose -= foot\n",
    "    left_s -= foot\n",
    "    right_s -= foot\n",
    "\n",
    "    # nose와 y축 사이 각도 계산 => theta => np.radians\n",
    "    angle = np.arctan2(nose[1], nose[0]) \n",
    "    if nose[1] < 0: \n",
    "        angle += 180\n",
    "    theta = np.radians(angle)\n",
    "\n",
    "    # left_s, right_s 회전 실행\n",
    "    rotated_left_s = rotate_point(left_s, theta)\n",
    "    rotated_right_s = rotate_point(right_s, theta)\n",
    "\n",
    "    print(f'rotated_left_s: {rotated_left_s}')\n",
    "    print(f'rotated_right_s: {rotated_right_s}')\n",
    "\n",
    "    if rotated_left_s[0] < rotated_right_s[0]:\n",
    "        return False\n",
    "    else: \n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ceb12-3e57-458d-adcf-0783695c46ed",
   "metadata": {},
   "source": [
    "# CAM VER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72533b26-1053-4b62-bc45-31a97e387b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ipynb\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def flip_detection_cam():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                continue\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # pose detection\n",
    "            results = pose.process(image)\n",
    "            if results.pose_landmarks:\n",
    "                \n",
    "                nose = np.array([results.pose_landmarks.landmark[0].x, results.pose_landmarks.landmark[0].y])\n",
    "                left_s = np.array([results.pose_landmarks.landmark[11].x, results.pose_landmarks.landmark[11].y])\n",
    "                right_s = np.array([results.pose_landmarks.landmark[12].x, results.pose_landmarks.landmark[12].y])\n",
    "                \n",
    "                # 수선의 발 좌표 구하기\n",
    "                foot = find_perpendicular_foot(nose, left_s, right_s)\n",
    "                \n",
    "                # detect flip\n",
    "                flip = is_flipped(foot, nose, left_s, right_s)\n",
    "                if flip: \n",
    "                    print('Flipped!')\n",
    "                else:\n",
    "                    print('NOT Flipped!')\n",
    "            else: \n",
    "                print('Cannot Detect')\n",
    "\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            cv2.imshow('camera',image)\n",
    "            \n",
    "            # for ipynb\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3dd4e548-0d5a-4ec9-bc23-5aa0b9c2ac11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotated_left_s: [-0.13235877  0.01842876]\n",
      "rotated_right_s: [ 0.21783169 -0.03032945]\n",
      "NOT Flipped!\n"
     ]
    }
   ],
   "source": [
    "flip_detection_cam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b541a-0f24-4a75-a0c1-81920ce73d8e",
   "metadata": {},
   "source": [
    "# VIDEO VER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de94527f-ebc4-4918-9f9e-acab6252dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ipynb\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def flip_detection_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                print(\"Ignoring empty camera frame.\")\n",
    "                break\n",
    "            image.flags.writeable = False\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # pose detection\n",
    "            results = pose.process(image)\n",
    "            if results.pose_landmarks:\n",
    "                \n",
    "                nose = np.array([results.pose_landmarks.landmark[0].x, results.pose_landmarks.landmark[0].y])\n",
    "                left_s = np.array([results.pose_landmarks.landmark[11].x, results.pose_landmarks.landmark[11].y])\n",
    "                right_s = np.array([results.pose_landmarks.landmark[12].x, results.pose_landmarks.landmark[12].y])\n",
    "                \n",
    "                # 수선의 발 좌표 구하기\n",
    "                foot = find_perpendicular_foot(nose, left_s, right_s)\n",
    "                \n",
    "                # detect flip\n",
    "                flip = is_flipped(foot, nose, left_s, right_s)\n",
    "                if flip: \n",
    "                    print('Flipped!')\n",
    "                else:\n",
    "                    print('NOT Flipped!')\n",
    "            else: \n",
    "                print('Cannot Detect')\n",
    "\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (480, 640))\n",
    "            cv2.imshow('video',image)\n",
    "            \n",
    "            # for ipynb\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            if cv2.waitKey(5) & 0xFF == 27:\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6d076d4-881e-437e-aec1-71f3bd2e96ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotated_left_s: [-0.081663    0.00812224]\n",
      "rotated_right_s: [ 0.13825097 -0.0137505 ]\n",
      "NOT Flipped!\n"
     ]
    }
   ],
   "source": [
    "flip_detection_video('flipping.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f32021f-7a83-4e0d-8eb5-295be5759e19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
